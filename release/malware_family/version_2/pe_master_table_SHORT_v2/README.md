# MABEL: [M]alware [A]nalysis [Be]nchmark for Artificial Intelligence and Machine [L]earning

## Description
MABEL dataset release VERSION 2.00. This dataset is an abbreviation of our initial full static binary analysis dataset specified at [MABEL Full Dataset](https://github.com/action-ai-institute/MABEL-dataset/tree/main/release/malware_family/version_2/pe_master_table_LONG_v2).
This dataset contains analysis of Windows 32-bit PE binary files associated to a malware family.  

## Contents
This release contains analysis from our framework specific to 400+ malware families and binaries associated to each malware family.  
The instances in this single dataset have been cleaned and all hex values have been converted to decimal.
This dataset is ready to be analyzed via Machine Learning models. 


#### Special thanks to vx-underground.org for providing the samples and malware family attribution in our dataset release. 

# Datatable Description


### The following describes features in this dataset:

| Feature   | Description | Example Data |
| --------  | ----------- | ------------ |
| sha256_hash	| sha-256 hash of the binary file	| 04195d9d2e4623d9e3818b60c00f5a57ce593441ab137c34c4368eda8b217944 |
 | clam_av_scan_results | results of clam-av scan of the binary. Clam-av is updated prior to scanning the binary. | Win.Malware.Delf-6737076-0 | 
 | yara_malware | yara_malware scan results  | suspicious_packer_section | 
 | family_name | name of malware family (if malware is attributed to a malware family) | Example_Family | 
 | sample_name | name of the malware analyzed | 04195d9d2e4623d9e3818b60c00f5a57ce593441ab137c34c4368eda8b217944 | 
 | md5_hash | md5 hash of the binary file | acd322299c4614f69147dc7254fe8c96 | 
 | sha1_hash | sha-1 hash of the binary file | 9271893e87ee85fa8ad476e4138aace1a10cf70c | 
 | sha224_hash | sha-224 hash of the binary file | fc841641134839c87d027d9446bc598f7552a91c0596ad53e287fae8 | 
 | sha384_hash | sha-384 hash of the binary file | a0d1e2c658b909f6b3e60754160e5e794521d0b4b21da7636fd6fb9e3c7d49ea6b6697fa989a99a3f1ea2ffefeb40a31 | 
 | sha512_hash | sha-512 hash of the binary file | 0cc4b3be4c2d9b9e42bc803457db2102a7baf4097d03a68e69b162100aedb6aa32052bd9908a6ce16a32b606e9e0a6f722da64557e47e94ff03e7496a7516800 | 
 | ssdeep | ssdeep similarity scan of the binary file | 24576:TrIZh50bPfJa1BWeA64Uv5WGdxC3uwvf8s+qp1nMk+0EEIWGyMlX38E1GOIBJiLB:T8H50bPEGUHxC3uW8sdbMOIvyaX38E1v | 
 | file_size | file size of binary (in human readable form) | 1401 kB | 
 | binary_file_size | raw size of binary in bytes | 1400832 | 
 | time_stamp | extracted binary creation date based on timestamp | 2023:04:19 06:42:01+00:00 | 
 | standardized_import_functions_sorted | We perform a stemming and lemmatization process to the API import functions in order to produce a pre-processed set of SORTED functions that that are ready for Bag-of-Words (BoW) e.g. TF-IDF and/or clustering e.g., K-Means clustering to help classify and characterize malware capabilities | beginpaint closehandle comparestring copyfile createevent createfile createfont createpen createprocess createsolidbrush createthread createwindow decodepointer defwindowproc deletecriticalsection deleteobject destroywindow |
 | count_import_functions_sorted | provides a total count of standardized_import_functions_sorted | 42 | 
 | import_functions_sequential | API import functions are referenced at specific virtual addresses in the disassembled objdump of each sample. We use the virtual address to provide a sequence of API import functions. Each complete string is delimited by a semicolon ';'. We provide this feature for use in embedding, Deep Learning, NLP, and LLM models that care about sequential data. | ADVAPI32.dll.GetUserNameW; NETAPI32.dll.NetUserGetInfo; KERNEL32.dll.Sleep; KERNEL32.dll.GetLogicalDrives; KERNEL32.dll.GetModuleHandleW; KERNEL32.dll.GetProcAddress; |
 | standardized_import_functions_sequential | We perform a stemming and lemmatization process to pre-process the sequential API import functions such that you have a sequenced list of API import functions ready for NLP, LLM modeling.| GetUserName; NetUserGetInfo; Sleep; GetLogicalDrives; GetModuleHandle; GetProcAddress; GetCurrentProcess; WinExec; LoadCursor; CreateSolidBrush; | 
 | count_import_functions_sequential | provides a total count of standardized_import_functions_sequential | 203 | 
 | peid | identifies packers or compilers using PEiD ("Portable Executable Identifier") | UPX -> www.upx.sourceforge.net; 1 | 
 | yara_packer | lists results from yara_packer scan | BobSoftMiniDelphiBoBBobSoft | 
 | yara_rat | lists results from from yara_rat scan | UPX | 
 | code_sections | identifies the sections that contain code and data for this binary | .data .rdata .reloc .rsrc .text .tls | 
 | code_section_sizes | identifies the sections that contain code and data for this binary along with respective size (in bytes) of each section | .data(2800) .rdata(10200)  .reloc(4200)  .rsrc(400)  .text(43600)  .tls(200)  | 
 | entropy_per_section | identifies entropy of each section in the binary | PE Header (6.99707: packed); UPX0 (2.9832: not packed); UPX1 (3.44151: not packed); .rsrc (0.179721: not packed); Overlay (6.72157: packed) | 
 | number_sections | identifies the number of code sections found in this binary | 6 | 
 | strings_sequential | strings are referenced at specific virtual addresses in the disassembled objdump of each sample. We use the virtual address to provide a sequence of strings extracted statically from each binary sample. Each complete string is delimited by a semicolon ';'. We provide this feature for use in embedding, Deep Learning, NLP, and LLM models that care about sequential data. | Hi YOUR PERSONAL FILES WERE ENCRYPTED BY 7ev3n-HONE$T; References as an aid to take correct decision : (click on the link for opening); References as an aid to take correct decision... |
 | count_strings_sequential | provides a count of all strings extracted from each sample. | 2058 |
 | standardized_strings_sequential | We pre-process these strings to give features ready for modeling: we apply spacy's stopword vector to remove stop words from the strings_sequential feature. Then, we lemmatize each set of strings using spacy's lemmatization module to further pre-process strings. Finally, we remove non alpha-numeric characters and then lowercase all strings such that the 'standardized' feature is ready for modeling via NLP, LLM, Sentence Transformers, etc. | hi personal file encrypt 7ev3nhonet reference aid correct decision click link open reference aid correct decision click link opening... |
 | count_standardized_strings_sequential | provides a count of all strings in standardized_strings_sequential feature.  | 1468 |







